{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e209b9-170d-4f46-bb4e-8c35446c011a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# With custom list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1da3bd-6b4d-43c6-b9d6-a65df454cc2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cálculo da coluna your list:\n",
      "Jaccard similarity: 0.7166386300897171\n",
      "Cosine similarity: 0.8268663552215036\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       0.33      1.00      0.50         1\n",
      "           2       0.89      0.57      0.70        14\n",
      "           3       1.00      1.00      1.00        38\n",
      "           4       0.50      1.00      0.67         3\n",
      "           5       0.50      0.50      0.50         2\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.48      0.71      0.57        17\n",
      "           8       1.00      1.00      1.00         4\n",
      "           9       0.29      1.00      0.44         2\n",
      "          10       0.80      1.00      0.89         4\n",
      "          11       1.00      1.00      1.00        12\n",
      "          12       0.60      1.00      0.75         9\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       0.62      1.00      0.77         5\n",
      "          15       1.00      0.40      0.57         5\n",
      "          16       0.83      1.00      0.91         5\n",
      "          17       0.50      1.00      0.67         1\n",
      "          18       1.00      0.75      0.86        12\n",
      "          19       0.50      0.50      0.50         2\n",
      "          20       1.00      1.00      1.00         1\n",
      "          21       0.60      1.00      0.75         3\n",
      "          22       0.43      1.00      0.60         3\n",
      "          23       0.50      0.67      0.57         3\n",
      "          24       0.62      1.00      0.77         5\n",
      "          25       0.81      1.00      0.89        21\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       0.50      0.50      0.50         2\n",
      "          28       1.00      1.00      1.00         1\n",
      "          29       0.87      1.00      0.93       124\n",
      "          30       0.80      1.00      0.89         4\n",
      "          31       1.00      1.00      1.00        17\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         1\n",
      "          35       0.81      1.00      0.90        13\n",
      "          36       0.91      1.00      0.95        67\n",
      "          37       0.73      1.00      0.84         8\n",
      "          38       0.25      1.00      0.40         1\n",
      "          39       0.80      1.00      0.89         4\n",
      "          40       1.00      1.00      1.00         1\n",
      "          41       0.17      1.00      0.29         1\n",
      "          42       1.00      1.00      1.00         1\n",
      "          43       0.50      1.00      0.67         2\n",
      "          44       1.00      0.67      0.80         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.67      1.00      0.80         2\n",
      "          47       1.00      1.00      1.00         1\n",
      "          48       0.81      0.91      0.86        23\n",
      "          49       0.66      0.61      0.64        96\n",
      "          50       0.81      1.00      0.90        13\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       0.80      0.89      0.84         9\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       0.83      0.86      0.84        22\n",
      "          55       0.75      0.75      0.75         4\n",
      "          56       0.25      1.00      0.40         1\n",
      "          57       1.00      1.00      1.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       1.00      1.00      1.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.86      1.00      0.92         6\n",
      "\n",
      "   micro avg       0.79      0.88      0.83       628\n",
      "   macro avg       0.70      0.84      0.74       628\n",
      "weighted avg       0.81      0.88      0.83       628\n",
      " samples avg       0.80      0.88      0.81       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna bode:\n",
      "Jaccard similarity: 0.08377482507025281\n",
      "Cosine similarity: 0.21418812296538223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.20      0.76      0.31        38\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.09      0.76      0.16        17\n",
      "           8       0.02      0.75      0.04         4\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       1.00      0.08      0.15        12\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.03      0.80      0.05         5\n",
      "          15       0.03      0.80      0.05         5\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.02      1.00      0.04         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.00      0.00      0.00        21\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.70      0.84      0.76       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       1.00      0.06      0.11        17\n",
      "          32       1.00      0.50      0.67         2\n",
      "          33       0.01      1.00      0.03         2\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00        13\n",
      "          36       0.35      0.76      0.48        67\n",
      "          37       0.00      0.00      0.00         8\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.01      1.00      0.01         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.03      0.33      0.06         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.01      1.00      0.03         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.13      0.83      0.22        23\n",
      "          49       0.54      0.83      0.65        96\n",
      "          50       0.00      0.00      0.00        13\n",
      "          51       0.01      1.00      0.03         2\n",
      "          52       0.00      0.00      0.00         9\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.12      0.51      0.20       628\n",
      "   macro avg       0.08      0.20      0.06       628\n",
      "weighted avg       0.33      0.51      0.34       628\n",
      " samples avg       0.13      0.55      0.18       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna vlt5:\n",
      "Jaccard similarity: 0.1816885861722817\n",
      "Cosine similarity: 0.29943590542802967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.67      0.42         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       1.00      0.39      0.57        38\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.25      0.29      0.27        17\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       1.00      0.50      0.67         2\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       1.00      0.50      0.67        12\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       1.00      0.20      0.33         5\n",
      "          15       0.00      0.00      0.00         5\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.50      0.08      0.14        12\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.62      0.24      0.34        21\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.91      0.86      0.88       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       1.00      0.47      0.64        17\n",
      "          32       1.00      0.50      0.67         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00        13\n",
      "          36       0.33      0.01      0.03        67\n",
      "          37       0.00      0.00      0.00         8\n",
      "          38       0.50      1.00      0.67         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       1.00      0.04      0.08        23\n",
      "          49       0.64      0.31      0.42        96\n",
      "          50       0.00      0.00      0.00        13\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         9\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       1.00      0.14      0.24        22\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.75      0.30      0.43       628\n",
      "   macro avg       0.19      0.10      0.11       628\n",
      "weighted avg       0.55      0.30      0.35       628\n",
      " samples avg       0.68      0.34      0.42       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna google:\n",
      "Jaccard similarity: 0.17303668161849317\n",
      "Cosine similarity: 0.3312483033832697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.50      0.07      0.12        14\n",
      "           3       0.61      0.74      0.67        38\n",
      "           4       0.08      0.33      0.13         3\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.42      0.29      0.34        17\n",
      "           8       0.09      0.50      0.15         4\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       1.00      0.25      0.40         4\n",
      "          11       0.12      1.00      0.21        12\n",
      "          12       0.21      0.33      0.26         9\n",
      "          13       0.02      0.33      0.04         3\n",
      "          14       0.06      0.40      0.11         5\n",
      "          15       0.04      0.60      0.08         5\n",
      "          16       0.07      0.40      0.12         5\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.01      0.50      0.02         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.67      0.40      0.50         5\n",
      "          25       0.00      0.00      0.00        21\n",
      "          26       0.07      1.00      0.13         1\n",
      "          27       0.02      0.50      0.04         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.74      0.90      0.81       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.13      0.76      0.22        17\n",
      "          32       0.02      1.00      0.03         2\n",
      "          33       0.04      1.00      0.07         2\n",
      "          34       0.02      1.00      0.04         1\n",
      "          35       0.50      0.31      0.38        13\n",
      "          36       0.52      0.84      0.64        67\n",
      "          37       0.08      0.12      0.10         8\n",
      "          38       0.04      1.00      0.08         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.07      1.00      0.13         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.24      0.39      0.30        23\n",
      "          49       0.60      0.97      0.74        96\n",
      "          50       0.00      0.00      0.00        13\n",
      "          51       0.07      1.00      0.13         2\n",
      "          52       0.36      0.44      0.40         9\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.02      1.00      0.05         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.31      0.67      0.42         6\n",
      "\n",
      "   micro avg       0.20      0.59      0.30       628\n",
      "   macro avg       0.12      0.31      0.12       628\n",
      "weighted avg       0.40      0.59      0.45       628\n",
      " samples avg       0.32      0.62      0.35       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna bloom:\n",
      "Jaccard similarity: 0.07541644052974761\n",
      "Cosine similarity: 0.20410129223652432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.50      0.06         6\n",
      "           1       0.02      1.00      0.04         1\n",
      "           2       0.08      0.57      0.14        14\n",
      "           3       0.26      0.71      0.38        38\n",
      "           4       0.03      1.00      0.06         3\n",
      "           5       0.01      0.50      0.02         2\n",
      "           6       0.01      1.00      0.03         1\n",
      "           7       0.13      0.82      0.22        17\n",
      "           8       0.04      1.00      0.08         4\n",
      "           9       0.02      1.00      0.04         2\n",
      "          10       0.03      0.75      0.06         4\n",
      "          11       0.08      0.58      0.13        12\n",
      "          12       0.07      0.78      0.13         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.02      0.40      0.04         5\n",
      "          15       0.02      0.40      0.04         5\n",
      "          16       0.03      0.60      0.06         5\n",
      "          17       0.01      1.00      0.02         1\n",
      "          18       0.09      0.75      0.17        12\n",
      "          19       0.01      0.50      0.02         2\n",
      "          20       0.01      1.00      0.02         1\n",
      "          21       0.03      1.00      0.06         3\n",
      "          22       0.05      1.00      0.09         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.05      1.00      0.10         5\n",
      "          25       0.14      0.48      0.22        21\n",
      "          26       0.01      1.00      0.02         1\n",
      "          27       0.02      1.00      0.04         2\n",
      "          28       0.01      1.00      0.03         1\n",
      "          29       0.70      0.67      0.69       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.13      0.71      0.22        17\n",
      "          32       0.01      0.50      0.02         2\n",
      "          33       0.01      0.50      0.02         2\n",
      "          34       0.01      1.00      0.02         1\n",
      "          35       0.07      0.54      0.13        13\n",
      "          36       0.45      0.67      0.54        67\n",
      "          37       0.03      0.38      0.06         8\n",
      "          38       0.01      1.00      0.02         1\n",
      "          39       0.04      0.75      0.08         4\n",
      "          40       0.01      1.00      0.02         1\n",
      "          41       0.02      1.00      0.03         1\n",
      "          42       0.01      1.00      0.02         1\n",
      "          43       0.01      0.50      0.02         2\n",
      "          44       0.03      1.00      0.07         3\n",
      "          45       0.01      1.00      0.02         1\n",
      "          46       0.01      0.50      0.02         2\n",
      "          47       0.01      1.00      0.02         1\n",
      "          48       0.13      0.35      0.19        23\n",
      "          49       0.54      0.67      0.60        96\n",
      "          50       0.07      0.38      0.12        13\n",
      "          51       0.02      0.50      0.03         2\n",
      "          52       0.09      0.89      0.16         9\n",
      "          53       0.02      1.00      0.04         2\n",
      "          54       0.16      0.45      0.23        22\n",
      "          55       0.01      0.25      0.02         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.01      1.00      0.02         1\n",
      "          58       0.01      1.00      0.02         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.02      0.67      0.04         3\n",
      "          61       0.01      1.00      0.02         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.01      1.00      0.02         1\n",
      "          64       0.04      0.67      0.08         6\n",
      "\n",
      "   micro avg       0.07      0.64      0.13       628\n",
      "   macro avg       0.06      0.69      0.09       628\n",
      "weighted avg       0.32      0.64      0.37       628\n",
      " samples avg       0.24      0.66      0.24       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna face:\n",
      "Jaccard similarity: 0.0\n",
      "Cosine similarity: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00        38\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00        17\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.00      0.00      0.00        12\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       0.00      0.00      0.00         5\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.00      0.00      0.00        21\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.00      0.00      0.00        17\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00        13\n",
      "          36       0.00      0.00      0.00        67\n",
      "          37       0.00      0.00      0.00         8\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00        23\n",
      "          49       0.00      0.00      0.00        96\n",
      "          50       0.00      0.00      0.00        13\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         9\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       628\n",
      "   macro avg       0.00      0.00      0.00       628\n",
      "weighted avg       0.00      0.00      0.00       628\n",
      " samples avg       0.00      0.00      0.00       628\n",
      "\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_final = pd.read_csv('Results_with_list.csv')\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "def extract_words(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [word.lower() for word in words]\n",
    "    return words\n",
    "\n",
    "def is_list_of_words(text):\n",
    "    words = extract_words(text)\n",
    "    return all(word.isalpha() for word in words)\n",
    "\n",
    "results_bode = []\n",
    "results_vlt5 = []\n",
    "results_google = []\n",
    "results_bloom = []\n",
    "results_face = []\n",
    "results_your = []\n",
    "default_text = []\n",
    "\n",
    "for text in df_final['Bode'].tolist():\n",
    "    results_bode.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['vlt5'].tolist():\n",
    "    results_vlt5.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['Google'].tolist():\n",
    "    results_google.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['BigScience'].tolist():\n",
    "    results_bloom.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['Facebook'].tolist():\n",
    "    results_face.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['your list'].tolist():\n",
    "    results_your.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['aspect'].tolist():\n",
    "    default_text.append(list(set(extract_words(text))))\n",
    "\n",
    "results_of_all = []\n",
    "results_of_all.extend(df_final['aspect'].tolist()+df_final['your list'].tolist()+results_bode+results_vlt5+results_google+results_bloom+results_face)\n",
    "\n",
    "results_of_all = [item for sublist in results_of_all for item in sublist]\n",
    "unique_elements_results = list(set(results_of_all))\n",
    "\n",
    "resultados = {\n",
    "    'your list': results_your,\n",
    "    'bode': results_bode,\n",
    "    'vlt5': results_vlt5,\n",
    "    'google': results_google,\n",
    "    'bloom': results_bloom,\n",
    "    'face': results_face\n",
    "}\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def counter_cosine_similarity(c1, c2):\n",
    "    terms = set(c1).union(c2)\n",
    "    dotprod = sum(c1.get(k, 0) * c2.get(k, 0) for k in terms)\n",
    "    magA = math.sqrt(sum(c1.get(k, 0)**2 for k in terms))\n",
    "    magB = math.sqrt(sum(c2.get(k, 0)**2 for k in terms))\n",
    "    return dotprod / (magA * magB)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import hamming_loss, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Criar um binarizador com todas as classes\n",
    "#mlb = MultiLabelBinarizer(classes=unique_elements_results)\n",
    "mlb = MultiLabelBinarizer()\n",
    "#mlb.fit(unique_elements_results)\n",
    "y_true_binarized = mlb.fit_transform(default_text)\n",
    "\n",
    "columns = ['your list', 'bode', 'vlt5', 'google', 'bloom', 'face']\n",
    "\n",
    "for column in columns:\n",
    "    jaccard_results = []\n",
    "    cosine_results = []\n",
    "    print(f'Cálculo da coluna {column}:')\n",
    "    # Binarizar as etiquetas\n",
    "    y_pred_binarized = mlb.transform(resultados[column])\n",
    "\n",
    "    # Calcular Hamming Loss\n",
    "    #hl = hamming_loss(y_true_binarized, y_pred_binarized)\n",
    "    #print(f'Hamming Loss: {hl}')\n",
    "\n",
    "    for x in range(len(default_text)):\n",
    "        jaccard_results.append(jaccard_similarity(default_text[x], resultados[column][x]))\n",
    "        if resultados[column][x] == []:\n",
    "            resultados[column][x].append('nan')\n",
    "        counterA = Counter(default_text[x])\n",
    "        counterB = Counter(resultados[column][x])\n",
    "        cosine_results.append(counter_cosine_similarity(counterA, counterB))\n",
    "        \n",
    "    print(f'Jaccard similarity: {sum(jaccard_results)/len(jaccard_results)}')\n",
    "    print(f'Cosine similarity: {sum(cosine_results)/len(cosine_results)}')\n",
    "    \n",
    "    print(classification_report(y_true_binarized, y_pred_binarized))\n",
    "    print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc883b-aea8-4a70-a7ba-43070862ad0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "source": [
    "# Without custom list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccfeed09-ab02-4888-aabb-0bf2fc375976",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cálculo da coluna merged:\n",
      "Jaccard similarity: 0.17964602926184337\n",
      "Cosine similarity: 0.35225444132027744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.89      0.57      0.70        14\n",
      "           3       1.00      1.00      1.00        38\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.48      0.71      0.57        17\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.00      0.00      0.00        12\n",
      "          12       0.60      1.00      0.75         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       0.00      0.00      0.00         5\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.81      1.00      0.89        21\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.87      1.00      0.93       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       1.00      1.00      1.00        17\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.81      1.00      0.90        13\n",
      "          36       0.91      1.00      0.95        67\n",
      "          37       0.00      0.00      0.00         8\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.81      0.91      0.86        23\n",
      "          49       0.66      0.61      0.64        96\n",
      "          50       0.81      1.00      0.90        13\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         9\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.83      0.86      0.84        22\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.82      0.67      0.74       628\n",
      "   macro avg       0.16      0.18      0.17       628\n",
      "weighted avg       0.62      0.67      0.64       628\n",
      " samples avg       0.78      0.68      0.70       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna bode:\n",
      "Jaccard similarity: 0.06121495351530945\n",
      "Cosine similarity: 0.15963906348247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.86      0.43      0.57        14\n",
      "           3       1.00      0.76      0.87        38\n",
      "           4       0.33      0.33      0.33         3\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.73      0.47      0.57        17\n",
      "           8       1.00      0.50      0.67         4\n",
      "           9       0.33      0.50      0.40         2\n",
      "          10       1.00      0.50      0.67         4\n",
      "          11       1.00      0.67      0.80        12\n",
      "          12       0.60      0.67      0.63         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.60      0.60      0.60         5\n",
      "          15       0.00      0.00      0.00         5\n",
      "          16       0.75      0.60      0.67         5\n",
      "          17       0.50      1.00      0.67         1\n",
      "          18       0.80      0.33      0.47        12\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       1.00      0.33      0.50         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.67      0.40      0.50         5\n",
      "          25       0.00      0.00      0.00        21\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       0.50      0.50      0.50         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.89      0.72      0.79       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       1.00      0.53      0.69        17\n",
      "          32       1.00      0.50      0.67         2\n",
      "          33       1.00      0.50      0.67         2\n",
      "          34       1.00      1.00      1.00         1\n",
      "          35       0.86      0.92      0.89        13\n",
      "          36       0.00      0.00      0.00        67\n",
      "          37       0.70      0.88      0.78         8\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       1.00      1.00      1.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       1.00      1.00      1.00         1\n",
      "          43       0.50      0.50      0.50         2\n",
      "          44       1.00      0.67      0.80         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       1.00      1.00      1.00         1\n",
      "          48       0.00      0.00      0.00        23\n",
      "          49       0.70      0.39      0.50        96\n",
      "          50       0.00      0.00      0.00        13\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.33      0.11      0.17         9\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       0.57      1.00      0.73         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      1.00      1.00         1\n",
      "          58       1.00      1.00      1.00         1\n",
      "          59       1.00      1.00      1.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       1.00      0.50      0.67         6\n",
      "\n",
      "   micro avg       0.80      0.41      0.54       628\n",
      "   macro avg       0.46      0.38      0.40       628\n",
      "weighted avg       0.57      0.41      0.47       628\n",
      " samples avg       0.66      0.42      0.48       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna vlt5:\n",
      "Jaccard similarity: 0.1427707407326971\n",
      "Cosine similarity: 0.2432042943517576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.50      0.07      0.12        14\n",
      "           3       1.00      0.16      0.27        38\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       1.00      0.06      0.11        17\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       1.00      0.50      0.67         2\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       1.00      0.17      0.29        12\n",
      "          12       1.00      0.11      0.20         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       1.00      0.40      0.57         5\n",
      "          15       0.00      0.00      0.00         5\n",
      "          16       1.00      0.20      0.33         5\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.00      0.00      0.00        21\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.91      0.83      0.87       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       1.00      0.18      0.30        17\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00        13\n",
      "          36       0.00      0.00      0.00        67\n",
      "          37       0.00      0.00      0.00         8\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00        23\n",
      "          49       0.50      0.03      0.06        96\n",
      "          50       0.00      0.00      0.00        13\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         9\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.87      0.20      0.33       628\n",
      "   macro avg       0.17      0.05      0.07       628\n",
      "weighted avg       0.44      0.20      0.24       628\n",
      " samples avg       0.65      0.23      0.33       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna google:\n",
      "Jaccard similarity: 0.19663998441172362\n",
      "Cosine similarity: 0.3091989429884021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       1.00      0.07      0.13        14\n",
      "           3       1.00      0.18      0.31        38\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.40      0.12      0.18        17\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       1.00      0.25      0.40         4\n",
      "          11       1.00      0.33      0.50        12\n",
      "          12       0.60      0.33      0.43         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       1.00      0.20      0.33         5\n",
      "          15       0.00      0.00      0.00         5\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       1.00      0.20      0.33         5\n",
      "          25       0.00      0.00      0.00        21\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.91      0.76      0.83       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       1.00      0.12      0.21        17\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       1.00      1.00      1.00         1\n",
      "          35       0.00      0.00      0.00        13\n",
      "          36       0.71      0.07      0.14        67\n",
      "          37       0.00      0.00      0.00         8\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00        23\n",
      "          49       0.76      0.61      0.68        96\n",
      "          50       0.00      0.00      0.00        13\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       1.00      0.44      0.62         9\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       1.00      0.33      0.50         6\n",
      "\n",
      "   micro avg       0.84      0.30      0.44       628\n",
      "   macro avg       0.21      0.08      0.10       628\n",
      "weighted avg       0.57      0.30      0.35       628\n",
      " samples avg       0.69      0.33      0.42       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna bloom:\n",
      "Jaccard similarity: 0.05139872207823497\n",
      "Cosine similarity: 0.138819062717662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       1.00      0.36      0.53        14\n",
      "           3       1.00      0.61      0.75        38\n",
      "           4       0.33      0.33      0.33         3\n",
      "           5       0.50      0.50      0.50         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.50      0.53      0.51        17\n",
      "           8       1.00      0.50      0.67         4\n",
      "           9       0.25      0.50      0.33         2\n",
      "          10       1.00      0.50      0.67         4\n",
      "          11       1.00      0.50      0.67        12\n",
      "          12       0.75      0.33      0.46         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.60      0.60      0.60         5\n",
      "          15       1.00      0.20      0.33         5\n",
      "          16       0.80      0.80      0.80         5\n",
      "          17       1.00      1.00      1.00         1\n",
      "          18       1.00      0.50      0.67        12\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.50      0.67      0.57         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.75      0.60      0.67         5\n",
      "          25       0.00      0.00      0.00        21\n",
      "          26       0.50      1.00      0.67         1\n",
      "          27       0.50      0.50      0.50         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.86      0.69      0.76       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       1.00      0.59      0.74        17\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         1\n",
      "          35       0.75      0.46      0.57        13\n",
      "          36       1.00      0.01      0.03        67\n",
      "          37       0.83      0.62      0.71         8\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       1.00      1.00      1.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       1.00      0.33      0.50         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00        23\n",
      "          49       0.67      0.41      0.51        96\n",
      "          50       0.00      0.00      0.00        13\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.60      0.33      0.43         9\n",
      "          53       1.00      0.50      0.67         2\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       1.00      0.50      0.67         4\n",
      "          56       0.33      1.00      0.50         1\n",
      "          57       0.50      1.00      0.67         1\n",
      "          58       1.00      1.00      1.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.80      0.67      0.73         6\n",
      "\n",
      "   micro avg       0.78      0.39      0.52       628\n",
      "   macro avg       0.47      0.36      0.38       628\n",
      "weighted avg       0.68      0.39      0.46       628\n",
      " samples avg       0.63      0.41      0.46       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna face:\n",
      "Jaccard similarity: 0.002783465682566417\n",
      "Cosine similarity: 0.006914237723738006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00        38\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00        17\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.00      0.00      0.00        12\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       0.00      0.00      0.00         5\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.00      0.00      0.00        21\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      0.08      0.15       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.00      0.00      0.00        17\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00        13\n",
      "          36       0.00      0.00      0.00        67\n",
      "          37       0.00      0.00      0.00         8\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00        23\n",
      "          49       1.00      0.02      0.04        96\n",
      "          50       0.00      0.00      0.00        13\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         9\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       1.00      0.02      0.04       628\n",
      "   macro avg       0.03      0.00      0.00       628\n",
      "weighted avg       0.35      0.02      0.04       628\n",
      " samples avg       0.07      0.01      0.02       628\n",
      "\n",
      "----------------------------------------------\n",
      "Cálculo da coluna keybert:\n",
      "Jaccard similarity: 0.19751451748734353\n",
      "Cosine similarity: 0.33300806996677673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.89      0.57      0.70        14\n",
      "           3       0.00      0.00      0.00        38\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.50      0.50      0.50         2\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00        17\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.00      0.00      0.00        12\n",
      "          12       0.00      0.00      0.00         9\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.62      1.00      0.77         5\n",
      "          15       0.00      0.00      0.00         5\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00        12\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.60      1.00      0.75         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.00      0.00      0.00        21\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.87      1.00      0.93       124\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.00      0.00      0.00        17\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         2\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00        13\n",
      "          36       0.91      1.00      0.95        67\n",
      "          37       0.00      0.00      0.00         8\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         4\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          44       0.00      0.00      0.00         3\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00        23\n",
      "          49       0.66      0.61      0.64        96\n",
      "          50       0.81      1.00      0.90        13\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         9\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         3\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.81      0.45      0.58       628\n",
      "   macro avg       0.09      0.10      0.09       628\n",
      "weighted avg       0.42      0.45      0.43       628\n",
      " samples avg       0.77      0.46      0.54       628\n",
      "\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_final = pd.read_csv('Results_without_list.csv')\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Função para extrair palavras de um texto\n",
    "def extract_words(text):\n",
    "    # Remover pontuação\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenizar\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # Converter para minúsculas\n",
    "    words = [word.lower() for word in words]\n",
    "    return words\n",
    "\n",
    "# Função para verificar se a saída é uma lista de palavras\n",
    "def is_list_of_words(text):\n",
    "    words = extract_words(text)\n",
    "    return all(word.isalpha() for word in words)\n",
    "    \n",
    "results_bode = []\n",
    "results_keybert = []\n",
    "results_vlt5 = []\n",
    "results_google = []\n",
    "results_bloom = []\n",
    "results_face = []\n",
    "results_merged = []\n",
    "default_text = []\n",
    "\n",
    "for text in df_final['Bode'].tolist():\n",
    "    results_bode.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['keybert'].tolist():\n",
    "    results_keybert.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['vlt5'].tolist():\n",
    "    results_vlt5.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['Google'].tolist():\n",
    "    results_google.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['BigScience'].tolist():\n",
    "    results_bloom.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['Facebook'].tolist():\n",
    "    results_face.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['merged'].tolist():\n",
    "    results_merged.append(list(set(extract_words(text))))\n",
    "\n",
    "for text in df_final['aspect'].tolist():\n",
    "    default_text.append(list(set(extract_words(text))))\n",
    "\n",
    "results_of_all = []\n",
    "results_of_all.extend(df_final['aspect'].tolist()+df_final['merged'].tolist()+results_vlt5+results_google+results_bloom+results_face)\n",
    "\n",
    "results_of_all = [item for sublist in results_of_all for item in sublist]\n",
    "unique_elements_results = list(set(results_of_all))\n",
    "\n",
    "resultados = {\n",
    "    'merged': results_merged,\n",
    "    'bode': results_bode,\n",
    "    'vlt5': results_vlt5,\n",
    "    'google': results_google,\n",
    "    'bloom': results_bloom,\n",
    "    'face': results_face,\n",
    "    'keybert': results_keybert\n",
    "}\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def counter_cosine_similarity(c1, c2):\n",
    "    terms = set(c1).union(c2)\n",
    "    dotprod = sum(c1.get(k, 0) * c2.get(k, 0) for k in terms)\n",
    "    magA = math.sqrt(sum(c1.get(k, 0)**2 for k in terms))\n",
    "    magB = math.sqrt(sum(c2.get(k, 0)**2 for k in terms))\n",
    "    return dotprod / (magA * magB)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import hamming_loss, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Criar um binarizador com todas as classes\n",
    "#mlb = MultiLabelBinarizer(classes=unique_elements_results)\n",
    "mlb = MultiLabelBinarizer()\n",
    "#mlb.fit(unique_elements_results)\n",
    "y_true_binarized = mlb.fit_transform(default_text)\n",
    "\n",
    "columns = ['merged', 'bode', 'vlt5', 'google', 'bloom', 'face', 'keybert']\n",
    "\n",
    "for column in columns:\n",
    "    jaccard_results = []\n",
    "    cosine_results = []\n",
    "    print(f'Cálculo da coluna {column}:')\n",
    "    # Binarizar as etiquetas\n",
    "    y_pred_binarized = mlb.transform(resultados[column])\n",
    "\n",
    "    # Calcular Hamming Loss\n",
    "    #hl = hamming_loss(y_true_binarized, y_pred_binarized)\n",
    "    #print(f'Hamming Loss: {hl}')\n",
    "\n",
    "    for x in range(len(default_text)):\n",
    "        jaccard_results.append(jaccard_similarity(default_text[x], resultados[column][x]))\n",
    "        if resultados[column][x] == []:\n",
    "            resultados[column][x].append('nan')\n",
    "        counterA = Counter(default_text[x])\n",
    "        counterB = Counter(resultados[column][x])\n",
    "        cosine_results.append(counter_cosine_similarity(counterA, counterB))\n",
    "        \n",
    "    print(f'Jaccard similarity: {sum(jaccard_results)/len(jaccard_results)}')\n",
    "    print(f'Cosine similarity: {sum(cosine_results)/len(cosine_results)}')\n",
    "    \n",
    "    print(classification_report(y_true_binarized, y_pred_binarized))\n",
    "    print('----------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
